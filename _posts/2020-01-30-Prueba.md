
# Redes Neuronales, introducción 

## la Inteligencia artificial

La Inteligencia Artificial se suele relacionar con robots que se comportan como humanos. Una definición más formal es la siguiente.

>Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving

Por lo tanto estamos hablando de máquinas que intentan simular ciertos comportamientos humanos. En realidad la inteligencia artificial es un tema mucho menos espectacular y exótico de lo que parece. La parte positiva es que, al mismo tiempo, también es mucho más asequible y real de lo que podríamos pensar.

**Machine Learning** es un campo dentro de la inteligencia artificial que se centra en modelos de aprendizaje. Estos modelos aprenden de los ejemplo que se les proporciona para detectar patrones y obtener predicciones. También son capaces de extraer información simplemente analizando un conjunto de datos.

>Machine Learning is the field of study that gives computers the ability to learn without
being explicitly programmed.
Arthur Samuel, 1959`


Las **redes neuronales** pertenecen al ámbito de Machine Learning. Hablamos de modelos que son capaces de aprender sin ser explicitamente programados. Se diferencian de otros modelos de machine learning porque tienen una estructura de capas más compleja que permite un aprendizaje más profundo. por este motivo, al trabajo con redes neuronales también se le conoce como Deep Learning. Gracias a esta capacidad las redes neuronales han conseguido resolver problemas que hace unos años parecían inalcanzable, como por ejemplo.

- Reconocimiento de imágenes: en este campo se han realizado avances sorprendentes a nivel de clasificación automática de imágenes, detección de objetos, segmentación, generación automáticas de imágenes (style transfer), super resolución, descripción automática de imágenes etc.
- Tratamiento de lenguaje natural (NLP): clasificación automática de documentos, análisis de sentimiento, traducciones de textos, generación automática de subtítulos en videos …
- Sistemas de recomendaciones: como los que utilizan las grandes compañías para ofrecerte productos basados en tu historial relacionado con el comportamiento de otros usuarios.

La buena noticia es que estás tecnologías no sólo son una realidad, sino que están al alcance de cualquiera.

## Objetivo del artículo
El contenido de este artículo se centra en dar una visión general de lo que son las redes neuronales. Está destinado a aquellas personas que no están familiarizadas con estas tecnologías o que quieren consolidar los unos conocimientos básicos. Intentaremos evitar, en la medida de lo posible, las demostraciones matemáticas complejas pero si trataremos de explicar cada uno de los mecanismo que conforman una red neuronal básica.




Comencemos.

## Aprendiendo mediante ejemplos
### Otra forma de abordar los problemas

La forma tradicional y más extendida de solucionar los problemas se basa en el desarrollo de algoritmos. 

>ALGORITMO:
"Conjunto ordenado de operaciones sistemáticas que permite hacer un cálculo y hallar la solución de un tipo de problemas"`


Para desarrollar un algoritmos tenemos que conocer todas las variables, dependencias, condiciones y situaciones que se pueden dar.
¿Qué sucede cuando nuestro problema es tan complejo que no somos capaces de conocer toda su casuística?

### Modelos de aprendizaje

En estos casos tenemos que plantear la solución de otra manera.

¿Cómo aprendemos cuando somos pequeños a distinguir los números?

Entre los profesores y nuestros padres nos bombardean a imágenes de números. Al final conseguimos distinguir unos de otros después de cientos y cientos de ejemplos.
No es un problema tan trivial porque cada uno tiene su propia forma de escribir los números.



Si lo analizamos un poco, no es fácil desarrollar un algoritmo que nos permita distinguir números manuscritos pero para nosotros, una vez aprendidos, es la tarea más simple del mundo.

A continuación os pongo algunos ejemplos de extraidos de MNIST.

![mnist](/images/mnist2.jpg)

[mnist:](http://yann.lecun.com/exdb/mnist/)
`base de datos de imágenes con 60.000 ejemplo de números manuscritos de tamaño 28x28 pixels. Se utiliza como base de entranamiento en explicaciones sencilla de tratamiento de imagenes.`

### Tipos de modelos

Dentro de los diferentes problemas que pueden resolver los modelos de apendizaje nos centrando en lo que llamamos modelos supervisados. Son modelos que aprenden de los ejemplos que se les proporcionan.
Tenemos dos tipos fundamentales de modelos
- Modelos de regresión: devuelven un valor númerico como por ejemplo el valor de compra de una casa. Como entrada del modelo tendremos información de la localización, año de construcción, distrito, metros cuadrados, número de habitaciones etc. Con esa información tenemos que predecir el precio de mercado de esa vivienda.
  
- Modelos de clasificación: devuelven la categoría a la que pertenece la información que le suministramos. En nuestro ejemplo de los números manuscriptos, con la información de los pixeles de la imagen, el modelo nos dirá cual es la categoría más probable (en definitiva, que número hemos escrito).





*¿Como simulamos esta forma de aprender basada en ejemplos?.*

Empezamos creando un modelo de aprendizaje al que vamos pasando ejemplos de lo que queremos predecir. Tomando el caso anterior le vamos mostrando imágenes de números y le decimos que número es el correcto. Para empezar, nuestro modelo no sabe absolutamente sobre números. Lo que tenemos que conseguir es que nuestro modelo se adapte (aprenda) de forma que cada vez la tasa acierto sea mayor. Esto es lo que llamamos entrenamiento de nuestro modelo.



Es similar a la forma que los humanos tenemos de aprender. Primero recopilamos un buen número de ejemplo (imágenes de números) con su correspondiente valor real (a que número corresponde). Luego le mostramos esa información a nuestro modelo hasta que consigamos que aprenda a distinguirlos. Esta es la forma de trabajar con redes neuronales y con la mayoría de los modelos de machine learning. Parece sencillo, ¿verdad?. Es un proceso iterativo de aprendizaje que finalizará cuando nuestro modelo nos proporcione un índice de aciertos satisfactorio.

Antes de pasar al siguiente apartado vamos a consolidar los conocimientos adquiridos y a relacionarlos con la terminología que se usa más frecuentemente en redes neuronales. Esto nos ayudará a entender mejor cualquier artículo o publicación que nos encontremos sobre el tema.

#### Entrada al modelo

Nuestro conjunto de imágenes es la entrada al modelo (input). Cada imagen tendrá una serie de valores para identificar cada pixel (tratamiento de imágenes). Si en lugar de identificar números, queremos predecir el precio de la vivienda tendremos que proporcionarle a nuestro modelo información sobre localización, tamaño, número de habitaciones, año de construcción etc.
Esta información tiene varios nombres.


>Estos valores de entrada se denominan variables independientes **(independent variable)**. Cuando tratamos de definir matemáticamente nuestro modelo a este conjunto de valores se le suele denominar como x.
	
El tratamiento de estos datos antes de pasarlos a cualquier modelo de aprendizaje es todo un mundo.

#### Valor real

Cuando hablamos del valor real nos referimos al número correcto que le hemos asignado a la imagen que estamos mostrando a nuestro modelo. Si la imagen es de un UNO le tenemos que decir a nuestro modelo que eso es un 1. Si el modelo predice un 7 es que está equivocado.
En el caso de calcular el precio de una vivienda nuestro valor real es el precio real de ese ejemplo de vivienda que estamos mostrando a nuestro modelo. Cuando más se ajuste el resultado obtenido por el modelo a este valor real mejor se comportará nuestro modelo.

>Estos valores se denominan  variable dependiente **dependent variable** o etiqueta **label**.

Es el conjunto de datos reales de nuestros ejemplos y que nuestro modelo tiene que aprender a predecir.

#### Nuestro Modelo

El modelo es básicamente un conjunto de operaciones que realizamos sobre la entrada para obtener una salida. Visto así se parece bastante a un algoritmo verdad?. Si ya sabemos las operaciones que hay que realizar sobre nuestra entrada de datos ya tenemos el problema resuelto.

En este caso no conocemos los coeficientes concretos que tenemos que utilizar nuestras operaciones. Es decir, sabemos que tenemos que multiplicar nuestra entrada por algo y sumarle algo más pero no sabemos exactamente los coeficientes que tenemos que utilizar para que nuestro modelo nos proporcione datos correctos.

Un ejemplo sencillo. Si tenemos la siguiente función

$f(x) = a·x + b$

No sabemos el valor de [a] ni [b] que mejor se ajustan a la función que buscamos.

Si nos dicen  $f(2)=5$ nos serviría $a=2$ y $b=1$ pero también $a=1$ y $b=3$ o $a=0$ y $b=5$
Si la información es $f(2)=5$ y $f(3) = 7$ solamente tenemos una solución  $a=2$ y $b=1$

En los casos reales las funciones son mucho más complejas y no existe una solución exacta. Tendremos que encontrar la solución que mejor se adapte a los datos de ejemplo que tenemos.

Comenzaremos con unos coeficientes aleatorios que iremos actualizando para ir mejorando las predicciones del modelo. Cuando estemos satisfechos de las predicciones de nuestro modelo podemos parar el proceso de aprendizaje y ya tendríamos nuestro modelo listo para predecir cualquier imagen de números que le pasemos.

Como veremos en el siguiente apartado realmente las operaciones básicas de nuestro modelo son precisamente multiplicaciones y sumas. No hay mucho más misterio en ese sentido. Es verdad que son multiplicaciones y suma de matrices. También es verdad que en modelos potentes estas matrices están compuestas por cientos de millones de parámetros.

Si representamos nuestro modelo con una fórmula matemática simple sería.

Si nuestro modelo es $f(x)=W∗x+b$     ($x$ es nuestro ejemplo de entrada)
La salida de nuestro modelo sería $\hat{y}=W∗x+b$

Los valores W y b son los parámetros de nuestro sistema y precisamente son los valores que nuestro modelo tiene que ir actualizar para mejorar sus predicciones. Más concretamente se definen como
- W: pesos (weight)  son los valores por los que multiplicamos nuestra entrada.
- b: bias corresponde con los valores que sumamos al final. Estos valores sirven para ajustar el modelo cuando los valores de x son cero.

El proceso de multiplicar la entrada por un valor y sumarle un segundo valor es lo que se denomina combinación linear. Si simplificamos el proceso y lo vemos como números simple en lugar de matrices vemos que podemos representar cualquier recta en un sistema de coordenadas simplemente seleccionando estos dos factores. El factor bias, en este caso, sería el punto de corte de la recta con el eje y (x=0)

### ¿Cómo de bueno es nuestro modelo?

Hemos comentado que x es la entrada a nuestro modelo (los ejemplos de imágenes) y que la variable y es el valor real. Si estamos diseñando un modelo para predecir un valor numérico es fácil de deducir que el error cometido es:

$error=(y − \hat{y})$ la diferencia entre el valor predicho por nuestro modelo y el valor real.

Esta es precisamente la definición de la función de error *loss function* o *cost function*. Bueno, normalmente se toma el valor absoluto o la diferencia al cuadrado. Tenemos que calcular el error medio cometido en todos nuestros ejemplos.
Para evitar que los errores positivos y negativos se compensen se suele utiliza el valor absoluto o la diferencia al cuadrado de cada error.

Típicas definiciones de funciones de error o de coste serían.


- MAE (mean absolute error):$\displaystyle \frac{\sum_{i=1}^{n}\|y − \hat{y}\|}{n}$, sumatorio del valor absoluto de cada uno de los errores dividido por el número de pruebas (n).

- RMSE (root mean square error):$\displaystyle \sqrt{\frac{\sum_{i=1}^{n}(y-\hat{y})^2}{n}}$, sumatorio del cuadrado de los errores dividido por el numero de ejemplos que tenemos (n). Finalmente obtiene la raiz cuadrada del número calculado.

La función de coste nos indica el error medio cometido por nuestro modelo al intentar predecir el valor real. Veremos que está función va a desempeñar un papel primordial a la hora de entranar el modelo.
### ¿Cómo entrenar el modelo?

Si queremos ir mejorando nuestro modelo la mejor idea es intentar minimizar el error que cometemos. Pues ese es el  proceso. El objetivo es modificar ligeramente nuestros parámetros para ir reduciendo el error cometido.o
