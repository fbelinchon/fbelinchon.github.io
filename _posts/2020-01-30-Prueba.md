
# Redes Neuronales, introducción 

## la Inteligencia artificial

La Inteligencia Artificial se suele relacionar con robots que se comportan como humanos. Es lo que nos muestran las series y películas de ciencia ficción. En realidad la inteligencia artificial y los modelos predictivos basados en redes neuronales es un tema mucho menos espectacular y exótico de lo que parece. La parte positiva es que, al mismo tiempo, también es mucho más asequible y real de lo que podríamos pensar.

Actualmente se están utilizando modelo de redes neuronales para resolver problemas que hace unos años parecían inalcanzable.

- Reconocimiento de imágenes: en este campo se han realizado avances sorprendentes a nivel de clasificación automática de imágenes, detección de objetos, segmentación, generación automáticas de imágenes (style transfer), super resolución, descripción automática de imágenes etc.
- Tratamiento de lenguaje natural (NLP): clasificación automática de documentos, análisis de sentimiento, traducciones de textos, generación automática de subtítulos en videos …
- Sistemas de recomendaciones: como los que utilizan las grandes compañías para ofrecerte productos basados en tu historial relacionado con el comportamiento de otros usuarios.

La buena noticia es que estás tecnologías no sólo son una realidad, sino que están al alcance de cualquiera.

## Objetivo del artículo
El contenido de este artículo se centra en dar una visión general de lo que son las redes neuronales. Está destinado a aquellas personas que no están familiarizadas con estas tecnologías o que quieren consolidar los conocimientos básicos.

Comencemos.

## Otra forma de abordar los problemas

La forma tradicional y más extendida de solucionar los problemas se basa en el desarrollo de algoritmos. 

`ALGORITMO:
"Conjunto ordenado de operaciones sistemáticas que permite hacer un cálculo y hallar la solución de un tipo de problemas"`


Para desarrollar un algoritmos tenemos que conocer todas las variables, dependencias, condiciones y situaciones que se pueden dar.
¿Qué sucede cuando nuestro problema es tan complejo que no somos capaces de conocer toda su casuística?

### Modelos de aprendizaje

En estos casos tenemos que plantear la solución de otra manera.

¿Cómo aprendemos cuando somos pequeños a distinguir los números?

Entre los profesores y nuestros padres nos bombardean a imágenes de números. Al final conseguimos distinguir unos de otros después de cientos y cientos de ejemplos.
No es un problema tan trivial porque cada uno tiene su propia forma de escribir los números. El uno por ejemplo. Unas veces es totalmente vertical, otras veces está inclinado, unas veces tiene un trazo inclinado superior, otras no.

Los cuatros y los nueves hay veces que son muy complicados de diferenciar cuando se escriben rápido, o el siete y el uno.

Si lo analizamos un poco, no es fácil desarrollar un algoritmo que nos permita distinguir números manuscritos pero para nosotros, una vez aprendidos, es la tarea más simple del mundo.

A continuación os pongo algunos ejemplos de extraidos de MNIST.

![mnist](/images/mnist2.jpg)



Vamos a intentar simular este comportamiento.

Empezamos creando un modelo de aprendizaje y le vamos pasando ejemplos de lo que queremos hacer. Tomando el caso anterior le vamos mostrando imágenes de números y le decimos que número es. Para empezar nuestro modelo no sabe absolutamente sobre los números. Lo que tenemos que conseguir es que nuestro modelo se adapte (aprenda) de forma que cada vez la tasa acierto sea mayor. Esto es lo que llamamos entrenamiento de nuestro modelo.

`Machine Learning is the field of study that gives computers the ability to learn without
being explicitly programmed.
Arthur Samuel, 1959`

Es similar a la forma que los humanos tenemos de aprender. Primero recopilamos un buen número de ejemplo (imágenes de números) con su correspondiente valor real (a que número corresponde). Luego le mostramos esa información a nuestro modelo hasta que consigamos que aprenda a distinguirlos. Esta es la forma de trabajar con redes neuronales y con la mayoría de los modelos de machine learning. Parece sencillo, verdad?. Es un proceso iterativo de aprendizaje que finalizará cuando nuestro modelo nos proporcione un índice de aciertos satisfactorio.

Antes de pasar al siguiente apartado vamos a consolidar los conocimientos adquiridos y a relacionarlos con la terminología que se usa más frecuentemente en redes neuronales. Esto nos ayudará a entender mejor cualquier artículo o publicación que nos encontremos sobre el tema.

#### Entrada al modelo

Nuestro conjunto de imágenes es la entrada al modelo (input). Cada imagen tendrá una serie de valores para identificar cada pixel (tratamiento de imágenes). Si en lugar de identificar números, queremos predecir el precio de la vivienda tendremos que proporcionarle a nuestro modelo información sobre localización, tamaño, número de habitaciones, año de construcción etc.
Esta información tiene varios nombres.

`Estos valores de entrada se denominan variables independientes (independent variable). Cuando tratamos de definir matemáticamente nuestro modelo a este conjunto de valores se le suele denominar como x.`
	
El tratamiento de estos datos antes de pasarlos a cualquier modelo de aprendizaje es todo un mundo.

#### Valor real

Cuando hablamos del valor real nos referimos al número correcto que le hemos asignado a la imagen que estamos mostrando a nuestro modelo. Si la imagen es de un UNO le tenemos que decir a nuestro modelo que eso es un 1. Si el modelo predice un 7 es que está equivocado.
En el caso de calcular el precio de una vivienda nuestro valor real es el precio real de ese ejemplo de vivienda que estamos mostrando a nuestro modelo. Cuando más se ajuste el resultado obtenido por el modelo a este valor real mejor se comportará nuestro modelo.

`Estos valores se denominan  variable dependiente **dependent variable** o etiqueta **label**.`

Es el conjunto de datos reales de nuestros ejemplos y que nuestro modelo tiene que aprender a predecir.

#### Nuestro Modelo

El modelo es básicamente un conjunto de operaciones que realizamos sobre la entrada para obtener una salida. Visto así se parece bastante a un algoritmo verdad?. Si ya sabemos las operaciones que hay que realizar sobre nuestra entrada de datos ya tenemos el problema resuelto.

En este caso no conocemos los coeficientes concretos que tenemos que utilizar nuestras operaciones. Es decir, sabemos que tenemos que multiplicar nuestra entrada por algo y sumarle algo más pero no sabemos exactamente los coeficientes que tenemos que utilizar para que nuestro modelo nos proporcione datos correctos.

Un ejemplo sencillo. Si tenemos la siguiente función

$f(x) = a·x + b$

No sabemos el valor de [a] ni [b] que mejor se ajustan a la función que buscamos.

Si nos dicen  $f(2)=5$ nos serviría $a=2$ y $b=1$ pero también $a=1$ y $b=3$ o $a=0$ y $b=5$
Si la información es $f(2)=5$ y $f(3) = 7$ solamente tenemos una solución  $a=2$ y $b=1$

Como no lo sabemos pues nos los inventamos y los generamos como valores aleatorios.

Esto parece una locura porque con valores aleatorios nunca vamos a conseguir el resultado correcto. El truco es que esos valores aleatorios se van modificando poco a poco según vamos pasando más ejemplos a nuestro modelo hasta que consigamos que reconozca correctamente las imágenes de números que le pasamos.

Este proceso de ir actualizando los valores aleatorios que hemos generado para obtener mejores predicciones es el proceso de aprendizaje. Cuando estemos satisfechos de las predicciones de nuestro modelo podemos parar el proceso de aprendizaje y ya tendríamos nuestro modelo listo para predecir cualquier imagen de números que le pasemos.

Como veremos en el siguiente apartado realmente las operaciones básicas de nuestro modelo son precisamente multiplicaciones y sumas. No hay mucho más misterio en ese sentido. Es verdad que son multiplicaciones y suma de matrices. También es verdad que en modelos potentes estas matrices están compuestas por cientos de millones de parámetros.

Si representamos nuestro modelo con una fórmula matemática simple sería.

Si nuestro modelo es $f(x)=W∗x+b$     ($x$ es nuestro ejemplo de entrada)
La salida de nuestro modelo sería $\hat{y}=W∗x+b$

Los valores W y b son los parámetros de nuestro sistema y precisamente son los valores que nuestro modelo tiene que ir actualizar para mejorar sus predicciones. Más concretamente se definen como
- W: pesos (weight)  son los valores por los que multiplicamos nuestra entrada.
- b: bias corresponde con los valores que sumamos al final. Estos valores sirven para ajustar el modelo cuando los valores de x son cero.

El proceso de multiplicar la entrada por un valor y sumarle un segundo valor es lo que se denomina combinación linear. Si simplificamos el proceso y lo vemos como números simple en lugar de matrices vemos que podemos representar cualquier recta en un sistema de coordenadas simplemente seleccionando estos dos factores. El factor bias, en este caso, sería el punto de corte de la recta con el eje y (x=0)

### ¿Cómo de bueno es nuestro modelo?

Hemos comentado que x es la entrada a nuestro modelo (los ejemplos de imágenes) y que la variable y es el valor real. Es fácil deducir que el error cometido por nuestro modelo es:

$ error=(y − \hat{y}) $

Esta es precisamente la definición de la función de error "loss function". Bueno, normalmente se toma el valor absoluto o la diferencia al cuadrado para tomar el valor absoluto del error.
Típicas definiciones de funciones de error o de coste serían.

$||a-b||$

- $||y − \hat{y}||$: valor absoluto
- $\sqrt{(y-\hat{y})^2}$: raiz cuadrada de la diferencia al cuadrado

### ¿Cómo entrenar el modelo?

Si queremos ir mejorando nuestro modelo la mejor idea es intentar minimizar el error que cometemos. Pues ese es el  proceso. El objetivo es modificar ligeramente nuestros parámetros para ir reduciendo el error cometido.o
